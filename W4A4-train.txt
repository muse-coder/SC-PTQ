==> Preparing dataset cifar10
Files already downloaded and verified
==> creating model 'resnet'
    Total params: 2.17M
loading pretrained model
module.conv1
Weight:   3.01%,  23.38%,  37.27%,  43.98%
module.layer1.0.conv1
Weight:   1.04%,  12.07%,  34.98%,  46.92%
module.layer1.0.conv2
Weight:   2.34%,  21.53%,  42.27%,  50.22%
module.layer1.1.conv1
Weight:   1.26%,  17.62%,  40.23%,  48.65%
module.layer1.1.conv2
Weight:   0.56%,  12.37%,  38.54%,  50.13%
module.layer1.2.conv1
Weight:   2.82%,  23.35%,  41.80%,  49.05%
module.layer1.2.conv2
Weight:   1.56%,  18.49%,  39.24%,  49.39%
module.layer2.0.conv1
Weight:   0.82%,  15.32%,  40.30%,  50.54%
module.layer2.0.conv2
Weight:   0.25%,  10.71%,  37.58%,  50.14%
module.layer2.0.downsample.0
Weight:   4.88%,  24.80%,  44.34%,  49.22%
module.layer2.1.conv1
Weight:   2.81%,  26.04%,  42.95%,  50.37%
module.layer2.1.conv2
Weight:   3.50%,  28.85%,  43.98%,  49.02%
module.layer2.2.conv1
Weight:   0.18%,  11.30%,  40.18%,  49.87%
module.layer2.2.conv2
Weight:   0.73%,  18.31%,  41.40%,  50.15%
module.layer3.0.conv1
Weight:   2.48%,  25.14%,  44.02%,  49.51%
module.layer3.0.conv2
Weight:   0.96%,  20.09%,  42.46%,  49.89%
module.layer3.0.downsample.0
Weight:   5.22%,  30.81%,  45.12%,  50.44%
module.layer3.1.conv1
Weight:   2.05%,  24.94%,  43.08%,  50.15%
module.layer3.1.conv2
Weight:   0.77%,  18.07%,  41.53%,  49.76%
module.layer3.2.conv1
Weight:   0.58%,  16.98%,  41.41%,  50.36%
module.layer3.2.conv2
Weight:   0.36%,  14.12%,  39.66%,  50.14%
module.fc
Weight:  25.31%,  54.22%,  50.00%,  54.38%
Bias:    40.00%,  60.00%,  40.00%,  50.00%
Accuracy: 89.78%

Epoch: [1 | 200] LR: 0.100000
########Model after pruning########
module.conv1
Weight:   3.01%,  23.38%,  37.27%,  43.98%
module.layer1.0.conv1
Weight:   1.04%,  12.07%,  34.98%,  46.92%
module.layer1.0.conv2
Weight:   2.34%,  21.53%,  42.27%,  50.22%
module.layer1.1.conv1
Weight:   1.26%,  17.62%,  40.23%,  48.65%
module.layer1.1.conv2
Weight:   0.56%,  12.37%,  38.54%,  50.13%
module.layer1.2.conv1
Weight:   2.82%,  23.35%,  41.80%,  49.05%
module.layer1.2.conv2
Weight:   1.56%,  18.49%,  39.24%,  49.39%
module.layer2.0.conv1
Weight:   0.82%,  15.32%,  40.30%,  50.54%
module.layer2.0.conv2
Weight:   0.25%,  10.71%,  37.58%,  50.14%
module.layer2.0.downsample.0
Weight:   4.88%,  24.80%,  44.34%,  49.22%
module.layer2.1.conv1
Weight:   2.81%,  26.04%,  42.95%,  50.37%
module.layer2.1.conv2
Weight:   3.50%,  28.85%,  43.98%,  49.02%
module.layer2.2.conv1
Weight:   0.18%,  11.30%,  40.18%,  49.87%
module.layer2.2.conv2
Weight:   0.73%,  18.31%,  41.40%,  50.15%
module.layer3.0.conv1
Weight:   2.48%,  25.14%,  44.02%,  49.51%
module.layer3.0.conv2
Weight:   0.96%,  20.09%,  42.46%,  49.89%
module.layer3.0.downsample.0
Weight:   5.22%,  30.81%,  45.12%,  50.44%
module.layer3.1.conv1
Weight:   2.05%,  24.94%,  43.08%,  50.15%
module.layer3.1.conv2
Weight:   0.77%,  18.07%,  41.53%,  49.76%
module.layer3.2.conv1
Weight:   0.58%,  16.98%,  41.41%,  50.36%
module.layer3.2.conv2
Weight:   0.36%,  14.12%,  39.66%,  50.14%
module.fc
Weight:  25.31%,  54.22%,  50.00%,  54.38%
Bias:    40.00%,  60.00%,  40.00%,  50.00%
 Test Loss after pruning:  0.49773874, Test Acc:  89.73
 Compression rate after pruning [8587072 / 1073384]:  8.00 X
Total Loss: 0.4519 | top1:  90.5500

Epoch: [2 | 200] LR: 0.100000
Total Loss: 0.4539 | top1:  90.2200

Epoch: [3 | 200] LR: 0.100000
Total Loss: 0.4925 | top1:  89.9900

Epoch: [4 | 200] LR: 0.100000
Total Loss: 0.4707 | top1:  90.2000

Epoch: [5 | 200] LR: 0.100000
Total Loss: 0.4281 | top1:  90.8500

Epoch: [6 | 200] LR: 0.100000
Total Loss: 0.4521 | top1:  90.6200

Epoch: [7 | 200] LR: 0.100000
Total Loss: 0.4430 | top1:  90.4300

Epoch: [8 | 200] LR: 0.100000
Total Loss: 0.4544 | top1:  90.2000

Epoch: [9 | 200] LR: 0.100000
Total Loss: 0.5106 | top1:  89.1800

Epoch: [10 | 200] LR: 0.100000
Total Loss: 0.4626 | top1:  90.1600

Epoch: [11 | 200] LR: 0.100000
Total Loss: 0.4337 | top1:  90.6300

Epoch: [12 | 200] LR: 0.100000
Total Loss: 0.4554 | top1:  90.7500

Epoch: [13 | 200] LR: 0.100000
Total Loss: 0.4805 | top1:  89.6000

Epoch: [14 | 200] LR: 0.100000
Total Loss: 0.4283 | top1:  90.7700

Epoch: [15 | 200] LR: 0.100000
Total Loss: 0.4380 | top1:  90.6800

Epoch: [16 | 200] LR: 0.100000
Total Loss: 0.4647 | top1:  90.0100

Epoch: [17 | 200] LR: 0.100000
Total Loss: 0.4515 | top1:  90.1400

Epoch: [18 | 200] LR: 0.100000
Total Loss: 0.5209 | top1:  88.6100

Epoch: [19 | 200] LR: 0.100000
Total Loss: 0.4244 | top1:  90.3000

Epoch: [20 | 200] LR: 0.100000
Total Loss: 0.4702 | top1:  89.1000

Epoch: [21 | 200] LR: 0.100000
Total Loss: 0.4523 | top1:  89.6100

Epoch: [22 | 200] LR: 0.100000
Total Loss: 0.4609 | top1:  90.1000

Epoch: [23 | 200] LR: 0.100000
Total Loss: 0.4945 | top1:  89.2000

Epoch: [24 | 200] LR: 0.100000
Total Loss: 0.4134 | top1:  89.9700

Epoch: [25 | 200] LR: 0.100000
Total Loss: 0.4587 | top1:  89.6700

Epoch: [26 | 200] LR: 0.100000
Total Loss: 0.4422 | top1:  89.7900

Epoch: [27 | 200] LR: 0.100000
Total Loss: 0.5150 | top1:  88.5500

Epoch: [28 | 200] LR: 0.100000
Total Loss: 0.4706 | top1:  89.1700

Epoch: [29 | 200] LR: 0.100000
Total Loss: 0.4509 | top1:  89.8200

Epoch: [30 | 200] LR: 0.100000
Total Loss: 0.4793 | top1:  88.7000

Epoch: [31 | 200] LR: 0.100000
Total Loss: 0.4800 | top1:  88.8300

Epoch: [32 | 200] LR: 0.100000
Total Loss: 0.4650 | top1:  89.3200

Epoch: [33 | 200] LR: 0.100000
Total Loss: 0.5467 | top1:  87.7300

Epoch: [34 | 200] LR: 0.100000
Total Loss: 0.4344 | top1:  89.9600

Epoch: [35 | 200] LR: 0.100000
Total Loss: 0.5999 | top1:  86.3800

Epoch: [36 | 200] LR: 0.100000
Total Loss: 0.4671 | top1:  89.1600

Epoch: [37 | 200] LR: 0.100000
Total Loss: 0.4291 | top1:  89.2600

Epoch: [38 | 200] LR: 0.100000
Total Loss: 0.4473 | top1:  88.5300

Epoch: [39 | 200] LR: 0.100000
Total Loss: 0.6399 | top1:  85.8200

Epoch: [40 | 200] LR: 0.100000
Total Loss: 0.5653 | top1:  86.6200

Epoch: [41 | 200] LR: 0.100000
Total Loss: 0.4719 | top1:  87.9000

Epoch: [42 | 200] LR: 0.100000
Total Loss: 0.4331 | top1:  88.7400

Epoch: [43 | 200] LR: 0.100000
Total Loss: 0.4511 | top1:  88.2000

Epoch: [44 | 200] LR: 0.100000
Total Loss: 0.6009 | top1:  86.2800

Epoch: [45 | 200] LR: 0.100000
Total Loss: 0.6488 | top1:  84.4400

Epoch: [46 | 200] LR: 0.100000
Total Loss: 0.6642 | top1:  83.5100

Epoch: [47 | 200] LR: 0.100000
Total Loss: 0.4791 | top1:  86.6400

Epoch: [48 | 200] LR: 0.100000
Total Loss: 0.4699 | top1:  86.5700

Epoch: [49 | 200] LR: 0.100000
Total Loss: 0.4879 | top1:  86.7400

Epoch: [50 | 200] LR: 0.100000
Total Loss: 0.5250 | top1:  85.9900

Epoch: [51 | 200] LR: 0.100000
Total Loss: 0.3798 | top1:  88.6700

Epoch: [52 | 200] LR: 0.100000
Total Loss: 0.5752 | top1:  86.1600

Epoch: [53 | 200] LR: 0.100000
Total Loss: 0.4707 | top1:  87.6900

Epoch: [54 | 200] LR: 0.100000
Total Loss: 0.5833 | top1:  85.9700

Epoch: [55 | 200] LR: 0.100000
Total Loss: 0.5340 | top1:  85.8200

Epoch: [56 | 200] LR: 0.100000
Total Loss: 0.4931 | top1:  86.5100

Epoch: [57 | 200] LR: 0.100000
Total Loss: 0.6400 | top1:  83.5600

Epoch: [58 | 200] LR: 0.100000
Total Loss: 0.5186 | top1:  86.1200

Epoch: [59 | 200] LR: 0.100000
Total Loss: 0.4274 | top1:  87.5600

Epoch: [60 | 200] LR: 0.100000
Total Loss: 0.4493 | top1:  87.7200

Epoch: [61 | 200] LR: 0.100000
Total Loss: 0.4690 | top1:  87.0700

Epoch: [62 | 200] LR: 0.100000
Total Loss: 0.4491 | top1:  87.7300

Epoch: [63 | 200] LR: 0.100000
Total Loss: 0.4828 | top1:  86.5300

Epoch: [64 | 200] LR: 0.100000
Total Loss: 0.5360 | top1:  84.1300

Epoch: [65 | 200] LR: 0.100000
Total Loss: 0.4603 | top1:  87.0100

Epoch: [66 | 200] LR: 0.100000
Total Loss: 0.7317 | top1:  81.9100

Epoch: [67 | 200] LR: 0.100000
Total Loss: 0.6081 | top1:  83.8900

Epoch: [68 | 200] LR: 0.100000
Total Loss: 0.5573 | top1:  85.4800

Epoch: [69 | 200] LR: 0.100000
Total Loss: 0.4786 | top1:  85.4500

Epoch: [70 | 200] LR: 0.100000
Total Loss: 0.4444 | top1:  87.4600

Epoch: [71 | 200] LR: 0.100000
Total Loss: 0.4721 | top1:  85.6100

Epoch: [72 | 200] LR: 0.100000
Total Loss: 0.5370 | top1:  84.0700

Epoch: [73 | 200] LR: 0.100000
Total Loss: 0.4825 | top1:  85.2500

Epoch: [74 | 200] LR: 0.100000
Total Loss: 0.7496 | top1:  80.2400

Epoch: [75 | 200] LR: 0.100000
Total Loss: 0.4756 | top1:  86.0800

Epoch: [76 | 200] LR: 0.100000
Total Loss: 0.6911 | top1:  81.5800

Epoch: [77 | 200] LR: 0.100000
Total Loss: 0.6168 | top1:  82.2300

Epoch: [78 | 200] LR: 0.100000
Total Loss: 0.8325 | top1:  78.7100

Epoch: [79 | 200] LR: 0.100000
Total Loss: 0.5899 | top1:  83.3000

Epoch: [80 | 200] LR: 0.100000
Total Loss: 0.5726 | top1:  83.4800

Epoch: [81 | 200] LR: 0.100000
Total Loss: 0.6781 | top1:  81.1600

Epoch: [82 | 200] LR: 0.100000
Total Loss: 0.5843 | top1:  82.0800

Epoch: [83 | 200] LR: 0.100000
Total Loss: 0.4451 | top1:  86.5800

Epoch: [84 | 200] LR: 0.100000
Total Loss: 0.5180 | top1:  84.3000

Epoch: [85 | 200] LR: 0.100000
Total Loss: 0.9488 | top1:  75.1900

Epoch: [86 | 200] LR: 0.100000
Total Loss: 0.6197 | top1:  81.8200

Epoch: [87 | 200] LR: 0.100000
Total Loss: 0.6228 | top1:  82.1100

Epoch: [88 | 200] LR: 0.100000
Total Loss: 0.5648 | top1:  82.1700

Epoch: [89 | 200] LR: 0.100000
Total Loss: 0.4832 | top1:  84.5200

Epoch: [90 | 200] LR: 0.100000
Total Loss: 0.4992 | top1:  84.2800

Epoch: [91 | 200] LR: 0.100000
Total Loss: 0.7128 | top1:  79.6800

Epoch: [92 | 200] LR: 0.100000
Total Loss: 0.6212 | top1:  81.4000

Epoch: [93 | 200] LR: 0.100000
Total Loss: 0.5932 | top1:  81.2300

Epoch: [94 | 200] LR: 0.100000
Total Loss: 0.8003 | top1:  78.1500

Epoch: [95 | 200] LR: 0.100000
Total Loss: 0.6436 | top1:  80.9000

Epoch: [96 | 200] LR: 0.100000
Total Loss: 0.6897 | top1:  80.0100

Epoch: [97 | 200] LR: 0.100000
Total Loss: 0.5925 | top1:  80.3500

Epoch: [98 | 200] LR: 0.100000
Total Loss: 0.9237 | top1:  73.7000

Epoch: [99 | 200] LR: 0.100000
Total Loss: 0.7250 | top1:  79.1200

Epoch: [100 | 200] LR: 0.100000
Total Loss: 1.0634 | top1:  73.0700

Epoch: [101 | 200] LR: 0.100000
########Model after pruning########
module.conv1
Weight:   0.93%,   4.86%,  27.55%,  40.51%,  42.59%
module.layer1.0.conv1
Weight:   0.04%,   3.12%,  21.31%,  46.79%
module.layer1.0.conv2
Weight:   2.21%,  27.34%,  49.18%
module.layer1.1.conv1
Weight:   0.87%,  20.36%,  48.61%
module.layer1.1.conv2
Weight:   0.52%,  19.92%,  49.35%
module.layer1.2.conv1
Weight:   4.34%,  29.47%,  48.39%
module.layer1.2.conv2
Weight:   1.43%,  22.83%,  49.65%
module.layer2.0.conv1
Weight:   0.56%,  19.73%,  48.78%
module.layer2.0.conv2
Weight:   0.04%,   8.98%,  49.19%
module.layer2.0.downsample.0
Weight:   0.78%,  12.50%,  37.50%,  50.20%
module.layer2.1.conv1
Weight:   0.02%,  11.70%,  50.65%
module.layer2.1.conv2
Weight:   8.90%,  52.12%
module.layer2.2.conv1
Weight:   0.02%,   7.48%,  50.69%
module.layer2.2.conv2
Weight:   0.01%,   3.42%,  49.20%
module.layer3.0.conv1
Weight:   2.68%,  48.68%
module.layer3.0.conv2
Weight:   0.28%,  31.73%
module.layer3.0.downsample.0
Weight:   1.76%,  30.22%,  50.00%
module.layer3.1.conv1
Weight:   0.17%,  27.89%
module.layer3.1.conv2
Weight:   0.04%,  19.73%
module.layer3.2.conv1
Weight:   0.12%,  19.95%
module.layer3.2.conv2
Weight:   7.80%
module.fc
Weight:   2.81%,  39.53%,  50.00%,  47.81%
Bias:    20.00%,  80.00%,  40.00%
 Test Loss after pruning:  1.12975253, Test Acc:  72.51
 Compression rate after pruning [8587072 / 560014]:  15.33 X
Total Loss: 0.3569 | top1:  88.7300

Epoch: [102 | 200] LR: 0.100000
Total Loss: 0.3666 | top1:  88.8900

Epoch: [103 | 200] LR: 0.100000
Total Loss: 0.3403 | top1:  89.0000

Epoch: [104 | 200] LR: 0.100000
Total Loss: 0.3444 | top1:  89.2000

Epoch: [105 | 200] LR: 0.100000
Total Loss: 0.3747 | top1:  88.3400

Epoch: [106 | 200] LR: 0.100000
Total Loss: 0.3798 | top1:  88.4600

Epoch: [107 | 200] LR: 0.100000
Total Loss: 0.3713 | top1:  88.7200

Epoch: [108 | 200] LR: 0.100000
Total Loss: 0.3528 | top1:  89.1800

Epoch: [109 | 200] LR: 0.100000
Total Loss: 0.3696 | top1:  88.9000

Epoch: [110 | 200] LR: 0.100000
Total Loss: 0.3954 | top1:  87.9900

Epoch: [111 | 200] LR: 0.100000
Total Loss: 0.3585 | top1:  89.2000

Epoch: [112 | 200] LR: 0.100000
Total Loss: 0.3750 | top1:  88.4200

Epoch: [113 | 200] LR: 0.100000
Total Loss: 0.3574 | top1:  88.6600

Epoch: [114 | 200] LR: 0.100000
Total Loss: 0.3254 | top1:  89.5400

Epoch: [115 | 200] LR: 0.100000
Total Loss: 0.3374 | top1:  89.5700

Epoch: [116 | 200] LR: 0.100000
Total Loss: 0.3746 | top1:  88.4900

Epoch: [117 | 200] LR: 0.100000
Total Loss: 0.4224 | top1:  87.9100

Epoch: [118 | 200] LR: 0.100000
Total Loss: 0.3742 | top1:  88.1600

Epoch: [119 | 200] LR: 0.100000
Total Loss: 0.3885 | top1:  88.3800

Epoch: [120 | 200] LR: 0.100000
Total Loss: 0.3388 | top1:  89.4900

Epoch: [121 | 200] LR: 0.100000
Total Loss: 0.4041 | top1:  88.7700

Epoch: [122 | 200] LR: 0.100000
Total Loss: 0.4531 | top1:  86.3300

Epoch: [123 | 200] LR: 0.100000
Total Loss: 0.3742 | top1:  88.6000

Epoch: [124 | 200] LR: 0.100000
Total Loss: 0.3506 | top1:  88.9500

Epoch: [125 | 200] LR: 0.100000
Total Loss: 0.4472 | top1:  87.0000

Epoch: [126 | 200] LR: 0.100000
Total Loss: 0.3858 | top1:  87.9700

Epoch: [127 | 200] LR: 0.100000
Total Loss: 0.4116 | top1:  87.1400

Epoch: [128 | 200] LR: 0.100000
Total Loss: 0.3438 | top1:  89.3000

Epoch: [129 | 200] LR: 0.100000
Total Loss: 0.4612 | top1:  86.6700

Epoch: [130 | 200] LR: 0.100000
Total Loss: 0.4272 | top1:  86.9500

Epoch: [131 | 200] LR: 0.100000
Total Loss: 0.4574 | top1:  87.0100

Epoch: [132 | 200] LR: 0.100000
Total Loss: 0.4227 | top1:  86.9900

Epoch: [133 | 200] LR: 0.100000
Total Loss: 0.3886 | top1:  88.0400

Epoch: [134 | 200] LR: 0.100000
Total Loss: 0.4730 | top1:  86.4000

Epoch: [135 | 200] LR: 0.100000
Total Loss: 0.4561 | top1:  86.3200

Epoch: [136 | 200] LR: 0.100000
Total Loss: 0.5040 | top1:  86.0000

Epoch: [137 | 200] LR: 0.100000
Total Loss: 0.5350 | top1:  84.5000

Epoch: [138 | 200] LR: 0.100000
Total Loss: 0.4221 | top1:  87.2000

Epoch: [139 | 200] LR: 0.100000
Total Loss: 0.4851 | top1:  86.0500

Epoch: [140 | 200] LR: 0.100000
Total Loss: 0.5346 | top1:  84.4000

Epoch: [141 | 200] LR: 0.100000
Total Loss: 0.4369 | top1:  86.8400

Epoch: [142 | 200] LR: 0.100000
Total Loss: 0.4044 | top1:  87.6800

Epoch: [143 | 200] LR: 0.100000
Total Loss: 0.4103 | top1:  87.5500

Epoch: [144 | 200] LR: 0.100000
Total Loss: 0.5407 | top1:  85.0300

Epoch: [145 | 200] LR: 0.100000
Total Loss: 0.4697 | top1:  86.4200

Epoch: [146 | 200] LR: 0.100000
Total Loss: 0.4638 | top1:  85.3900

Epoch: [147 | 200] LR: 0.100000
Total Loss: 0.5299 | top1:  84.3700

Epoch: [148 | 200] LR: 0.100000
Total Loss: 0.8495 | top1:  77.8300

Epoch: [149 | 200] LR: 0.100000
Total Loss: 0.6462 | top1:  81.4400

Epoch: [150 | 200] LR: 0.100000
Total Loss: 0.6958 | top1:  79.3000

Epoch: [151 | 200] LR: 0.100000
Total Loss: 0.5614 | top1:  82.5400

Epoch: [152 | 200] LR: 0.100000
Total Loss: 0.6639 | top1:  78.1000

Epoch: [153 | 200] LR: 0.100000
Total Loss: 0.4755 | top1:  84.6200

Epoch: [154 | 200] LR: 0.100000
Total Loss: 0.7338 | top1:  79.3600

Epoch: [155 | 200] LR: 0.100000
Total Loss: 0.9465 | top1:  74.0600

Epoch: [156 | 200] LR: 0.100000
Total Loss: 0.6017 | top1:  80.1400

Epoch: [157 | 200] LR: 0.100000
Total Loss: 0.7471 | top1:  76.4700

Epoch: [158 | 200] LR: 0.100000
Total Loss: 0.7449 | top1:  77.1700

Epoch: [159 | 200] LR: 0.100000
Total Loss: 0.7840 | top1:  76.3600

Epoch: [160 | 200] LR: 0.100000
Total Loss: 0.6361 | top1:  79.4100

Epoch: [161 | 200] LR: 0.100000
Total Loss: 0.6043 | top1:  80.8400

Epoch: [162 | 200] LR: 0.100000
Total Loss: 0.7401 | top1:  78.8800

Epoch: [163 | 200] LR: 0.100000
Total Loss: 0.5301 | top1:  82.6200

Epoch: [164 | 200] LR: 0.100000
Total Loss: 0.8839 | top1:  73.6600

Epoch: [165 | 200] LR: 0.100000
Total Loss: 1.3076 | top1:  68.6200

Epoch: [166 | 200] LR: 0.100000
Total Loss: 0.7894 | top1:  75.0400

Epoch: [167 | 200] LR: 0.100000
Total Loss: 0.7239 | top1:  75.7700

Epoch: [168 | 200] LR: 0.100000
Total Loss: 0.8275 | top1:  73.8900

Epoch: [169 | 200] LR: 0.100000
Total Loss: 0.9794 | top1:  72.2500

Epoch: [170 | 200] LR: 0.100000
Total Loss: 0.6268 | top1:  79.5900

Epoch: [171 | 200] LR: 0.100000
Total Loss: 0.6844 | top1:  77.4000

Epoch: [172 | 200] LR: 0.100000
Total Loss: 1.0031 | top1:  72.3100

Epoch: [173 | 200] LR: 0.100000
Total Loss: 0.6830 | top1:  77.9500

Epoch: [174 | 200] LR: 0.100000
Total Loss: 0.7392 | top1:  77.8800

Epoch: [175 | 200] LR: 0.100000
Total Loss: 1.1468 | top1:  69.0800

Epoch: [176 | 200] LR: 0.100000
Total Loss: 1.2428 | top1:  69.9600

Epoch: [177 | 200] LR: 0.100000
Total Loss: 1.4878 | top1:  62.1800

Epoch: [178 | 200] LR: 0.100000
Total Loss: 1.2924 | top1:  68.8700

Epoch: [179 | 200] LR: 0.100000
Total Loss: 0.8696 | top1:  72.5900

Epoch: [180 | 200] LR: 0.100000
Total Loss: 0.5818 | top1:  81.0200

Epoch: [181 | 200] LR: 0.100000
Total Loss: 1.1542 | top1:  69.3500

Epoch: [182 | 200] LR: 0.100000
Total Loss: 0.5764 | top1:  80.4300

Epoch: [183 | 200] LR: 0.100000
Total Loss: 0.7862 | top1:  76.1300

Epoch: [184 | 200] LR: 0.100000
Total Loss: 0.6779 | top1:  79.0100

Epoch: [185 | 200] LR: 0.100000
Total Loss: 0.7600 | top1:  76.9500

Epoch: [186 | 200] LR: 0.100000
Total Loss: 0.5949 | top1:  81.8700

Epoch: [187 | 200] LR: 0.100000
Total Loss: 0.8293 | top1:  76.6700

Epoch: [188 | 200] LR: 0.100000
Total Loss: 0.8233 | top1:  75.7800

Epoch: [189 | 200] LR: 0.100000
Total Loss: 1.9245 | top1:  59.6700

Epoch: [190 | 200] LR: 0.100000
Total Loss: 0.9749 | top1:  71.9200

Epoch: [191 | 200] LR: 0.100000
Total Loss: 0.6883 | top1:  79.4200

Epoch: [192 | 200] LR: 0.100000
Total Loss: 0.6974 | top1:  78.4300

Epoch: [193 | 200] LR: 0.100000
Total Loss: 0.7123 | top1:  77.7800

Epoch: [194 | 200] LR: 0.100000
Total Loss: 0.6728 | top1:  77.0900

Epoch: [195 | 200] LR: 0.100000
Total Loss: 1.0991 | top1:  69.5100

Epoch: [196 | 200] LR: 0.100000
Total Loss: 0.6792 | top1:  78.2000

Epoch: [197 | 200] LR: 0.100000
Total Loss: 0.7851 | top1:  74.8000

Epoch: [198 | 200] LR: 0.100000
Total Loss: 0.8625 | top1:  75.4700

Epoch: [199 | 200] LR: 0.100000
Total Loss: 0.8140 | top1:  73.2100

Epoch: [200 | 200] LR: 0.100000
Total Loss: 0.8779 | top1:  73.4500
Final checkpoint:
module.conv1
Weight:   0.46%,   4.40%,  24.54%,  38.89%,  41.44%,  43.29%
module.layer1.0.conv1
Weight:   0.04%,   3.60%,  22.35%,  45.27%
module.layer1.0.conv2
Weight:   0.09%,   9.29%,  45.49%
module.layer1.1.conv1
Weight:   0.04%,   4.47%,  41.80%
module.layer1.1.conv2
Weight:   0.04%,   4.34%,  41.49%
module.layer1.2.conv1
Weight:   0.17%,  13.15%,  46.09%
module.layer1.2.conv2
Weight:   0.04%,   7.03%,  45.14%
module.layer2.0.conv1
Weight:   0.02%,   4.82%,  44.77%
module.layer2.0.conv2
Weight:   0.97%,  36.82%
module.layer2.0.downsample.0
Weight:   0.98%,  11.91%,  37.30%,  49.41%
module.layer2.1.conv1
Weight:   0.60%,  36.36%
module.layer2.1.conv2
Weight:  16.08%
module.layer2.2.conv1
Weight:   0.85%,  38.69%
module.layer2.2.conv2
Weight:   0.09%,  28.37%
module.layer3.0.conv1
Weight:   9.94%
module.layer3.0.conv2
Weight:   4.79%
module.layer3.0.downsample.0
Weight:   0.05%,  11.52%,  50.63%
module.layer3.1.conv1
Weight:   2.59%
module.layer3.1.conv2
Weight:   1.80%
module.layer3.2.conv1
Weight:   2.25%
module.layer3.2.conv2
Weight:   0.46%
module.fc
Weight:   6.56%,  30.78%,  46.09%,  51.09%
Bias:    20.00%,  80.00%
 Final compression rate [8587072 / 348468]:  24.64 X
Total Loss: 0.8720 | top1:  74.1200
Best acc:
90.85
