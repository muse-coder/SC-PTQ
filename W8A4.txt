==> Preparing dataset cifar10
Files already downloaded and verified
==> creating model 'resnet'
    Total params: 4.34M
loading pretrained model
module.conv1
Weight:   3.01%,  19.68%,  34.03%,  38.19%,  42.36%,  48.38%,  46.76%,  46.30%
module.layer1.0.conv1
Weight:   1.04%,  10.46%,  27.95%,  38.19%,  43.14%,  45.14%,  46.22%,  48.35%
module.layer1.0.conv2
Weight:   2.34%,  18.62%,  36.37%,  44.88%,  46.53%,  49.65%,  49.00%,  51.00%
module.layer1.1.conv1
Weight:   1.26%,  15.28%,  32.47%,  41.62%,  47.48%,  48.44%,  48.57%,  49.31%
module.layer1.1.conv2
Weight:   0.56%,  10.33%,  31.94%,  41.58%,  45.44%,  47.87%,  49.61%,  49.83%
module.layer1.2.conv1
Weight:   2.82%,  20.53%,  36.15%,  44.10%,  45.96%,  47.05%,  48.74%,  49.87%
module.layer1.2.conv2
Weight:   1.56%,  15.67%,  33.42%,  42.97%,  46.09%,  47.92%,  49.09%,  49.74%
module.layer2.0.conv1
Weight:   0.82%,  12.96%,  33.44%,  42.80%,  46.25%,  49.31%,  49.59%,  50.52%
module.layer2.0.conv2
Weight:   0.25%,   8.69%,  29.83%,  41.41%,  46.17%,  48.51%,  49.14%,  50.23%
module.layer2.0.downsample.0
Weight:   4.88%,  22.27%,  38.48%,  43.55%,  48.24%,  48.83%,  49.80%,  50.59%
module.layer2.1.conv1
Weight:   2.81%,  22.99%,  38.31%,  45.05%,  46.84%,  49.24%,  50.31%,  49.13%
module.layer2.1.conv2
Weight:   3.50%,  25.78%,  38.78%,  45.01%,  47.67%,  49.58%,  49.46%,  49.71%
module.layer2.2.conv1
Weight:   0.18%,   9.29%,  32.03%,  42.09%,  46.90%,  49.21%,  49.82%,  50.02%
module.layer2.2.conv2
Weight:   0.73%,  15.43%,  35.28%,  43.63%,  46.99%,  48.91%,  49.95%,  49.63%
module.layer3.0.conv1
Weight:   2.48%,  22.08%,  38.95%,  43.98%,  46.96%,  48.06%,  49.24%,  50.18%
module.layer3.0.conv2
Weight:   0.96%,  17.15%,  36.56%,  43.32%,  47.40%,  48.68%,  49.88%,  49.73%
module.layer3.0.downsample.0
Weight:   5.22%,  28.12%,  39.99%,  46.34%,  48.58%,  48.19%,  49.80%,  49.32%
module.layer3.1.conv1
Weight:   2.05%,  22.06%,  37.72%,  43.93%,  47.00%,  48.90%,  49.88%,  50.10%
module.layer3.1.conv2
Weight:   0.77%,  15.45%,  35.14%,  42.76%,  47.05%,  48.74%,  49.64%,  50.05%
module.layer3.2.conv1
Weight:   0.58%,  14.18%,  35.24%,  43.30%,  46.69%,  48.29%,  49.29%,  50.39%
module.layer3.2.conv2
Weight:   0.36%,  11.78%,  32.73%,  42.03%,  46.22%,  49.02%,  49.39%,  50.20%
module.fc
Weight:  25.31%,  51.72%,  48.59%,  53.12%,  54.06%,  50.47%,  53.59%,  50.47%
Bias:    40.00%,  50.00%,  50.00%,  50.00%,  70.00%,  50.00%,  40.00%,  40.00%
Accuracy: 91.12%

Epoch: [1 | 350] LR: 0.100000
########Model after pruning########
module.conv1
Weight:   3.01%,  19.68%,  34.03%,  38.19%,  42.36%,  48.38%,  46.76%,  46.30%
module.layer1.0.conv1
Weight:   1.04%,  10.46%,  27.95%,  38.19%,  43.14%,  45.14%,  46.22%,  48.35%
module.layer1.0.conv2
Weight:   2.34%,  18.62%,  36.37%,  44.88%,  46.53%,  49.65%,  49.00%,  51.00%
module.layer1.1.conv1
Weight:   1.26%,  15.28%,  32.47%,  41.62%,  47.48%,  48.44%,  48.57%,  49.31%
module.layer1.1.conv2
Weight:   0.56%,  10.33%,  31.94%,  41.58%,  45.44%,  47.87%,  49.61%,  49.83%
module.layer1.2.conv1
Weight:   2.82%,  20.53%,  36.15%,  44.10%,  45.96%,  47.05%,  48.74%,  49.87%
module.layer1.2.conv2
Weight:   1.56%,  15.67%,  33.42%,  42.97%,  46.09%,  47.92%,  49.09%,  49.74%
module.layer2.0.conv1
Weight:   0.82%,  12.96%,  33.44%,  42.80%,  46.25%,  49.31%,  49.59%,  50.52%
module.layer2.0.conv2
Weight:   0.25%,   8.69%,  29.83%,  41.41%,  46.17%,  48.51%,  49.14%,  50.23%
module.layer2.0.downsample.0
Weight:   4.88%,  22.27%,  38.48%,  43.55%,  48.24%,  48.83%,  49.80%,  50.59%
module.layer2.1.conv1
Weight:   2.81%,  22.99%,  38.31%,  45.05%,  46.84%,  49.24%,  50.31%,  49.13%
module.layer2.1.conv2
Weight:   3.50%,  25.78%,  38.78%,  45.01%,  47.67%,  49.58%,  49.46%,  49.71%
module.layer2.2.conv1
Weight:   0.18%,   9.29%,  32.03%,  42.09%,  46.90%,  49.21%,  49.82%,  50.02%
module.layer2.2.conv2
Weight:   0.73%,  15.43%,  35.28%,  43.63%,  46.99%,  48.91%,  49.95%,  49.63%
module.layer3.0.conv1
Weight:   2.48%,  22.08%,  38.95%,  43.98%,  46.96%,  48.06%,  49.24%,  50.18%
module.layer3.0.conv2
Weight:   0.96%,  17.15%,  36.56%,  43.32%,  47.40%,  48.68%,  49.88%,  49.73%
module.layer3.0.downsample.0
Weight:   5.22%,  28.12%,  39.99%,  46.34%,  48.58%,  48.19%,  49.80%,  49.32%
module.layer3.1.conv1
Weight:   2.05%,  22.06%,  37.72%,  43.93%,  47.00%,  48.90%,  49.88%,  50.10%
module.layer3.1.conv2
Weight:   0.77%,  15.45%,  35.14%,  42.76%,  47.05%,  48.74%,  49.64%,  50.05%
module.layer3.2.conv1
Weight:   0.58%,  14.18%,  35.24%,  43.30%,  46.69%,  48.29%,  49.29%,  50.39%
module.layer3.2.conv2
Weight:   0.36%,  11.78%,  32.73%,  42.03%,  46.22%,  49.02%,  49.39%,  50.20%
module.fc
Weight:  25.31%,  51.72%,  48.59%,  53.12%,  54.06%,  50.47%,  53.59%,  50.47%
Bias:    40.00%,  50.00%,  50.00%,  50.00%,  70.00%,  50.00%,  40.00%,  40.00%
 Test Loss after pruning:  0.40535517, Test Acc:  91.05
 Compression rate after pruning [8587072 / 2146768]:  4.00 X
Total Loss: 0.4570 | top1:  88.5900

Epoch: [2 | 350] LR: 0.100000
Total Loss: 0.5304 | top1:  87.3200

Epoch: [3 | 350] LR: 0.100000
Total Loss: 0.4654 | top1:  87.8700

Epoch: [4 | 350] LR: 0.100000
Total Loss: 0.5092 | top1:  86.6400

Epoch: [5 | 350] LR: 0.100000
Total Loss: 0.5696 | top1:  84.7800

Epoch: [6 | 350] LR: 0.100000
Total Loss: 0.5883 | top1:  84.7200

Epoch: [7 | 350] LR: 0.100000
Total Loss: 0.4493 | top1:  86.8500

Epoch: [8 | 350] LR: 0.100000
Total Loss: 0.5423 | top1:  84.6100

Epoch: [9 | 350] LR: 0.100000
Total Loss: 0.6970 | top1:  80.0600

Epoch: [10 | 350] LR: 0.100000
Total Loss: 0.6273 | top1:  82.0000

Epoch: [11 | 350] LR: 0.100000
Total Loss: 0.4808 | top1:  84.8300

Epoch: [12 | 350] LR: 0.100000
Total Loss: 0.6685 | top1:  79.7700

Epoch: [13 | 350] LR: 0.100000
Total Loss: 0.7059 | top1:  78.4100

Epoch: [14 | 350] LR: 0.100000
Total Loss: 0.5368 | top1:  81.8700

Epoch: [15 | 350] LR: 0.100000
Total Loss: 0.7561 | top1:  76.8500

Epoch: [16 | 350] LR: 0.100000
Total Loss: 0.7517 | top1:  75.5500

Epoch: [17 | 350] LR: 0.100000
Total Loss: 0.6860 | top1:  77.7500

Epoch: [18 | 350] LR: 0.100000
Total Loss: 0.8712 | top1:  73.6000

Epoch: [19 | 350] LR: 0.100000
Total Loss: 0.7877 | top1:  75.0800

Epoch: [20 | 350] LR: 0.100000
Total Loss: 0.7755 | top1:  74.4600

Epoch: [21 | 350] LR: 0.100000
Total Loss: 0.8194 | top1:  73.8500

Epoch: [22 | 350] LR: 0.100000
Total Loss: 0.6289 | top1:  78.6100

Epoch: [23 | 350] LR: 0.100000
Total Loss: 0.7199 | top1:  76.8500

Epoch: [24 | 350] LR: 0.100000
Total Loss: 0.8955 | top1:  72.6800

Epoch: [25 | 350] LR: 0.100000
Total Loss: 0.7855 | top1:  74.3800

Epoch: [26 | 350] LR: 0.100000
Total Loss: 0.7007 | top1:  76.5300

Epoch: [27 | 350] LR: 0.100000
Total Loss: 1.1390 | top1:  65.6300

Epoch: [28 | 350] LR: 0.100000
Total Loss: 0.6189 | top1:  79.3300

Epoch: [29 | 350] LR: 0.100000
Total Loss: 0.8417 | top1:  72.4700

Epoch: [30 | 350] LR: 0.100000
Total Loss: 0.6719 | top1:  76.7600

Epoch: [31 | 350] LR: 0.100000
Total Loss: 1.0996 | top1:  67.7300

Epoch: [32 | 350] LR: 0.100000
Total Loss: 1.0976 | top1:  69.1400

Epoch: [33 | 350] LR: 0.100000
Total Loss: 0.9617 | top1:  70.3800

Epoch: [34 | 350] LR: 0.100000
Total Loss: 0.8962 | top1:  71.8800

Epoch: [35 | 350] LR: 0.100000
Total Loss: 0.9297 | top1:  69.3300

Epoch: [36 | 350] LR: 0.100000
Total Loss: 1.1267 | top1:  65.7700

Epoch: [37 | 350] LR: 0.100000
Total Loss: 0.8830 | top1:  72.4400

Epoch: [38 | 350] LR: 0.100000
Total Loss: 0.7254 | top1:  76.1100

Epoch: [39 | 350] LR: 0.100000
Total Loss: 0.9056 | top1:  69.8900

Epoch: [40 | 350] LR: 0.100000
Total Loss: 0.9507 | top1:  70.3800

Epoch: [41 | 350] LR: 0.100000
Total Loss: 0.6669 | top1:  77.7400

Epoch: [42 | 350] LR: 0.100000
Total Loss: 0.7481 | top1:  75.5500

Epoch: [43 | 350] LR: 0.100000
Total Loss: 0.8391 | top1:  73.3800

Epoch: [44 | 350] LR: 0.100000
Total Loss: 0.8570 | top1:  73.4000

Epoch: [45 | 350] LR: 0.100000
Total Loss: 1.2715 | top1:  63.6200

Epoch: [46 | 350] LR: 0.100000
Total Loss: 0.6106 | top1:  79.5700

Epoch: [47 | 350] LR: 0.100000
Total Loss: 0.6587 | top1:  79.1600

Epoch: [48 | 350] LR: 0.100000
Total Loss: 0.7899 | top1:  75.2700

Epoch: [49 | 350] LR: 0.100000
Total Loss: 0.6576 | top1:  77.7800

Epoch: [50 | 350] LR: 0.100000
Total Loss: 0.9066 | top1:  72.7200

Epoch: [51 | 350] LR: 0.100000
Total Loss: 0.7668 | top1:  76.4100

Epoch: [52 | 350] LR: 0.100000
Total Loss: 0.8316 | top1:  73.9700

Epoch: [53 | 350] LR: 0.100000
Total Loss: 0.6834 | top1:  78.0100

Epoch: [54 | 350] LR: 0.100000
Total Loss: 0.7823 | top1:  75.2300

Epoch: [55 | 350] LR: 0.100000
Total Loss: 0.7431 | top1:  76.1700

Epoch: [56 | 350] LR: 0.100000
Total Loss: 0.6545 | top1:  77.6300

Epoch: [57 | 350] LR: 0.100000
Total Loss: 0.8093 | top1:  74.4200

Epoch: [58 | 350] LR: 0.100000
Total Loss: 0.6611 | top1:  78.5200

Epoch: [59 | 350] LR: 0.100000
Total Loss: 1.4013 | top1:  64.0300

Epoch: [60 | 350] LR: 0.100000
Total Loss: 0.7710 | top1:  74.0800

Epoch: [61 | 350] LR: 0.100000
Total Loss: 0.6586 | top1:  78.5800

Epoch: [62 | 350] LR: 0.100000
Total Loss: 0.8677 | top1:  72.9200

Epoch: [63 | 350] LR: 0.100000
Total Loss: 0.6739 | top1:  77.7500

Epoch: [64 | 350] LR: 0.100000
Total Loss: 0.7555 | top1:  75.9100

Epoch: [65 | 350] LR: 0.100000
Total Loss: 0.7131 | top1:  76.1900

Epoch: [66 | 350] LR: 0.100000
Total Loss: 0.6880 | top1:  77.5400

Epoch: [67 | 350] LR: 0.100000
Total Loss: 0.6691 | top1:  78.7700

Epoch: [68 | 350] LR: 0.100000
Total Loss: 0.5994 | top1:  80.2600

Epoch: [69 | 350] LR: 0.100000
Total Loss: 0.7416 | top1:  75.9500

Epoch: [70 | 350] LR: 0.100000
Total Loss: 0.8969 | top1:  72.7900

Epoch: [71 | 350] LR: 0.100000
Total Loss: 0.6117 | top1:  79.3500

Epoch: [72 | 350] LR: 0.100000
Total Loss: 0.6847 | top1:  77.3800

Epoch: [73 | 350] LR: 0.100000
Total Loss: 0.7382 | top1:  75.8000

Epoch: [74 | 350] LR: 0.100000
Total Loss: 0.7025 | top1:  77.4300

Epoch: [75 | 350] LR: 0.100000
Total Loss: 0.8248 | top1:  74.4900

Epoch: [76 | 350] LR: 0.100000
Total Loss: 0.6355 | top1:  78.9200

Epoch: [77 | 350] LR: 0.100000
Total Loss: 0.6458 | top1:  78.4300

Epoch: [78 | 350] LR: 0.100000
Total Loss: 0.7076 | top1:  76.4600

Epoch: [79 | 350] LR: 0.100000
Total Loss: 0.6774 | top1:  78.1900

Epoch: [80 | 350] LR: 0.100000
Total Loss: 0.8945 | top1:  74.1000

Epoch: [81 | 350] LR: 0.100000
Total Loss: 0.5940 | top1:  79.7100

Epoch: [82 | 350] LR: 0.100000
Total Loss: 0.9131 | top1:  72.3200

Epoch: [83 | 350] LR: 0.100000
Total Loss: 0.6629 | top1:  78.6800

Epoch: [84 | 350] LR: 0.100000
Total Loss: 0.8297 | top1:  75.5600

Epoch: [85 | 350] LR: 0.100000
Total Loss: 0.6737 | top1:  78.3700

Epoch: [86 | 350] LR: 0.100000
Total Loss: 0.5925 | top1:  80.2500

Epoch: [87 | 350] LR: 0.100000
Total Loss: 0.6983 | top1:  76.8800

Epoch: [88 | 350] LR: 0.100000
Total Loss: 0.9140 | top1:  74.3700

Epoch: [89 | 350] LR: 0.100000
Total Loss: 0.9132 | top1:  70.9600

Epoch: [90 | 350] LR: 0.100000
Total Loss: 0.8087 | top1:  73.7500

Epoch: [91 | 350] LR: 0.100000
Total Loss: 0.6898 | top1:  75.7200

Epoch: [92 | 350] LR: 0.100000
Total Loss: 0.6504 | top1:  78.9500

Epoch: [93 | 350] LR: 0.100000
Total Loss: 0.6797 | top1:  77.8000

Epoch: [94 | 350] LR: 0.100000
Total Loss: 0.6945 | top1:  77.0700

Epoch: [95 | 350] LR: 0.100000
Total Loss: 0.7446 | top1:  75.2500

Epoch: [96 | 350] LR: 0.100000
Total Loss: 0.6829 | top1:  78.4900

Epoch: [97 | 350] LR: 0.100000
Total Loss: 0.7523 | top1:  73.9300

Epoch: [98 | 350] LR: 0.100000
Total Loss: 0.6214 | top1:  78.9100

Epoch: [99 | 350] LR: 0.100000
Total Loss: 0.6007 | top1:  79.8500

Epoch: [100 | 350] LR: 0.100000
Total Loss: 1.3397 | top1:  66.7200

Epoch: [101 | 350] LR: 0.100000
########Model after pruning########
module.conv1
Weight:  11.57%,  27.31%,  35.42%,  40.51%,  42.13%,  49.54%,  48.15%,  44.21%
module.layer1.0.conv1
Weight:   0.09%,   3.43%,  15.10%,  28.08%,  37.50%,  44.14%,  46.79%,  46.35%
module.layer1.0.conv2
Weight:   0.04%,   2.04%,  16.19%,  32.34%,  42.93%,  44.62%,  50.22%,  51.74%
module.layer1.1.conv1
Weight:   1.00%,   8.59%,  24.87%,  39.76%,  45.83%,  49.18%,  48.31%
module.layer1.1.conv2
Weight:   0.35%,   9.72%,  27.60%,  40.80%,  46.44%,  50.22%,  51.17%
module.layer1.2.conv1
Weight:   0.22%,   3.95%,  19.62%,  34.07%,  43.66%,  46.27%,  48.78%,  49.05%
module.layer1.2.conv2
Weight:   2.21%,  15.71%,  34.24%,  42.01%,  47.14%,  48.70%,  49.31%
module.layer2.0.conv1
Weight:   0.54%,  11.68%,  30.45%,  43.58%,  46.09%,  49.96%,  51.02%
module.layer2.0.conv2
Weight:   0.13%,   4.68%,  23.80%,  39.69%,  44.69%,  47.74%,  50.36%
module.layer2.0.downsample.0
Weight:   1.56%,  15.04%,  32.03%,  41.99%,  45.90%,  46.09%,  50.98%,  49.61%
module.layer2.1.conv1
Weight:   0.01%,   1.97%,  17.08%,  35.34%,  45.65%,  48.62%,  49.57%
module.layer2.1.conv2
Weight:   0.01%,   0.72%,  15.00%,  34.61%,  46.12%,  48.58%,  49.67%
module.layer2.2.conv1
Weight:   0.24%,   4.60%,  24.15%,  39.55%,  43.96%,  48.56%,  49.97%
module.layer2.2.conv2
Weight:   0.03%,   1.46%,  14.51%,  34.90%,  44.37%,  47.78%,  50.26%
module.layer3.0.conv1
Weight:   0.33%,   7.88%,  30.35%,  43.33%,  48.24%,  50.20%
module.layer3.0.conv2
Weight:   0.04%,   1.63%,   8.97%,  30.14%,  43.68%,  49.26%
module.layer3.0.downsample.0
Weight:   0.10%,   2.88%,  17.09%,  37.70%,  44.73%,  47.46%,  49.02%,  51.76%
module.layer3.1.conv1
Weight:   0.00%
module.layer3.1.conv2
Weight:   0.00%
module.layer3.2.conv1
Weight:   0.00%
module.layer3.2.conv2
Weight:   0.00%
module.fc
Weight:  12.66%,  30.47%,  41.88%,  46.72%,  49.22%,  44.53%,  47.97%,  50.62%
Bias:    20.00%,  50.00%,  40.00%,  40.00%,  20.00%,  40.00%,  50.00%
 Test Loss after pruning:  1.33972892, Test Acc:  66.72
 Compression rate after pruning [8587072 / 946374]:  9.07 X
Total Loss: 0.5044 | top1:  83.3200

Epoch: [102 | 350] LR: 0.100000
Total Loss: 0.5043 | top1:  83.2800

Epoch: [103 | 350] LR: 0.100000
Total Loss: 0.5216 | top1:  82.5500

Epoch: [104 | 350] LR: 0.100000
Total Loss: 0.4751 | top1:  84.3200

Epoch: [105 | 350] LR: 0.100000
Total Loss: 0.4642 | top1:  84.0300

Epoch: [106 | 350] LR: 0.100000
Total Loss: 0.5163 | top1:  83.0900

Epoch: [107 | 350] LR: 0.100000
Total Loss: 0.6493 | top1:  80.1200

Epoch: [108 | 350] LR: 0.100000
Total Loss: 0.5517 | top1:  81.8600

Epoch: [109 | 350] LR: 0.100000
Total Loss: 0.6813 | top1:  79.0200

Epoch: [110 | 350] LR: 0.100000
Total Loss: 0.5294 | top1:  82.9100

Epoch: [111 | 350] LR: 0.100000
Total Loss: 0.6236 | top1:  80.2400

Epoch: [112 | 350] LR: 0.100000
Total Loss: 0.9428 | top1:  72.4700

Epoch: [113 | 350] LR: 0.100000
Total Loss: 0.6315 | top1:  79.5600

Epoch: [114 | 350] LR: 0.100000
Total Loss: 0.5864 | top1:  80.7400

Epoch: [115 | 350] LR: 0.100000
Total Loss: 1.1002 | top1:  72.0200

Epoch: [116 | 350] LR: 0.100000
Total Loss: 0.5729 | top1:  80.0800

Epoch: [117 | 350] LR: 0.100000
Total Loss: 0.5994 | top1:  80.0700

Epoch: [118 | 350] LR: 0.100000
Total Loss: 0.7453 | top1:  76.8500

Epoch: [119 | 350] LR: 0.100000
Total Loss: 1.3274 | top1:  63.8000

Epoch: [120 | 350] LR: 0.100000
Total Loss: 0.6972 | top1:  77.6600

Epoch: [121 | 350] LR: 0.100000
Total Loss: 0.7368 | top1:  76.5900

Epoch: [122 | 350] LR: 0.100000
Total Loss: 0.7572 | top1:  76.1400

Epoch: [123 | 350] LR: 0.100000
Total Loss: 0.5411 | top1:  81.1600

Epoch: [124 | 350] LR: 0.100000
Total Loss: 0.5770 | top1:  80.5900

Epoch: [125 | 350] LR: 0.100000
Total Loss: 0.7443 | top1:  75.6600

Epoch: [126 | 350] LR: 0.100000
Total Loss: 0.6759 | top1:  77.2800

Epoch: [127 | 350] LR: 0.100000
Total Loss: 0.9492 | top1:  73.7300

Epoch: [128 | 350] LR: 0.100000
Total Loss: 0.5116 | top1:  82.8400

Epoch: [129 | 350] LR: 0.100000
Total Loss: 0.9377 | top1:  72.1500

Epoch: [130 | 350] LR: 0.100000
Total Loss: 0.6724 | top1:  78.2000

Epoch: [131 | 350] LR: 0.100000
Total Loss: 0.7207 | top1:  75.5200

Epoch: [132 | 350] LR: 0.100000
Total Loss: 0.7170 | top1:  77.1500

Epoch: [133 | 350] LR: 0.100000
Total Loss: 0.7057 | top1:  76.6600

Epoch: [134 | 350] LR: 0.100000
Total Loss: 0.6233 | top1:  79.1200

Epoch: [135 | 350] LR: 0.100000
Total Loss: 0.8506 | top1:  73.3200

Epoch: [136 | 350] LR: 0.100000
Total Loss: 0.9242 | top1:  72.0300

Epoch: [137 | 350] LR: 0.100000
Total Loss: 0.6616 | top1:  79.2500

Epoch: [138 | 350] LR: 0.100000
Total Loss: 0.7571 | top1:  75.5400

Epoch: [139 | 350] LR: 0.100000
Total Loss: 0.6585 | top1:  78.3700

Epoch: [140 | 350] LR: 0.100000
Total Loss: 0.6781 | top1:  78.5500

Epoch: [141 | 350] LR: 0.100000
Total Loss: 0.7562 | top1:  76.4900

Epoch: [142 | 350] LR: 0.100000
Total Loss: 0.6341 | top1:  79.2900

Epoch: [143 | 350] LR: 0.100000
Total Loss: 0.6136 | top1:  80.4000

Epoch: [144 | 350] LR: 0.100000
Total Loss: 1.8425 | top1:  62.5900

Epoch: [145 | 350] LR: 0.100000
Total Loss: 0.8725 | top1:  73.2900

Epoch: [146 | 350] LR: 0.100000
Total Loss: 0.6179 | top1:  79.1500

Epoch: [147 | 350] LR: 0.100000
Total Loss: 0.8090 | top1:  73.9200

Epoch: [148 | 350] LR: 0.100000
Total Loss: 0.6937 | top1:  76.6100

Epoch: [149 | 350] LR: 0.100000
Total Loss: 0.5894 | top1:  80.6300

Epoch: [150 | 350] LR: 0.100000
Total Loss: 0.8299 | top1:  73.9300

Epoch: [151 | 350] LR: 0.100000
Total Loss: 0.7559 | top1:  74.4600

Epoch: [152 | 350] LR: 0.100000
Total Loss: 0.7202 | top1:  77.9800

Epoch: [153 | 350] LR: 0.100000
Total Loss: 1.0186 | top1:  69.3200

Epoch: [154 | 350] LR: 0.100000
Total Loss: 0.9739 | top1:  72.8000

Epoch: [155 | 350] LR: 0.100000
Total Loss: 0.6052 | top1:  79.6800

Epoch: [156 | 350] LR: 0.100000
Total Loss: 0.7043 | top1:  77.6700

Epoch: [157 | 350] LR: 0.100000
Total Loss: 0.6322 | top1:  77.9500

Epoch: [158 | 350] LR: 0.100000
Total Loss: 0.6471 | top1:  78.9100

Epoch: [159 | 350] LR: 0.100000
Total Loss: 1.0220 | top1:  71.9400

Epoch: [160 | 350] LR: 0.100000
Total Loss: 1.0800 | top1:  69.4500

Epoch: [161 | 350] LR: 0.100000
Total Loss: 0.8402 | top1:  74.6000

Epoch: [162 | 350] LR: 0.100000
Total Loss: 0.9576 | top1:  72.0800

Epoch: [163 | 350] LR: 0.100000
Total Loss: 0.7325 | top1:  76.7200

Epoch: [164 | 350] LR: 0.100000
Total Loss: 0.8349 | top1:  76.2900

Epoch: [165 | 350] LR: 0.100000
Total Loss: 0.7755 | top1:  75.0700

Epoch: [166 | 350] LR: 0.100000
Total Loss: 0.7573 | top1:  76.0500

Epoch: [167 | 350] LR: 0.100000
Total Loss: 0.5702 | top1:  80.8900

Epoch: [168 | 350] LR: 0.100000
Total Loss: 0.6130 | top1:  79.6300

Epoch: [169 | 350] LR: 0.100000
Total Loss: 0.5474 | top1:  81.6700

Epoch: [170 | 350] LR: 0.100000
Total Loss: 0.9948 | top1:  69.3600

Epoch: [171 | 350] LR: 0.100000
Total Loss: 0.7766 | top1:  76.4900

Epoch: [172 | 350] LR: 0.100000
Total Loss: 0.7244 | top1:  76.8300

Epoch: [173 | 350] LR: 0.100000
Total Loss: 0.7699 | top1:  76.4500

Epoch: [174 | 350] LR: 0.100000
Total Loss: 0.5814 | top1:  80.8200

Epoch: [175 | 350] LR: 0.100000
Total Loss: 0.6005 | top1:  79.6000

Epoch: [176 | 350] LR: 0.100000
Total Loss: 0.8359 | top1:  74.9200

Epoch: [177 | 350] LR: 0.100000
Total Loss: 0.7375 | top1:  76.1600

Epoch: [178 | 350] LR: 0.100000
Total Loss: 0.6875 | top1:  77.4900

Epoch: [179 | 350] LR: 0.100000
Total Loss: 0.6118 | top1:  79.6600

Epoch: [180 | 350] LR: 0.100000
Total Loss: 0.9026 | top1:  72.6600

Epoch: [181 | 350] LR: 0.100000
Total Loss: 0.6170 | top1:  80.6400

Epoch: [182 | 350] LR: 0.100000
Total Loss: 0.8110 | top1:  75.1200

Epoch: [183 | 350] LR: 0.100000
Total Loss: 0.9234 | top1:  72.4600

Epoch: [184 | 350] LR: 0.100000
Total Loss: 0.6748 | top1:  78.5800

Epoch: [185 | 350] LR: 0.100000
Total Loss: 0.7456 | top1:  76.0500

Epoch: [186 | 350] LR: 0.100000
Total Loss: 0.9781 | top1:  71.8900

Epoch: [187 | 350] LR: 0.100000
Total Loss: 0.6507 | top1:  78.3200

Epoch: [188 | 350] LR: 0.100000
Total Loss: 0.5289 | top1:  82.2400

Epoch: [189 | 350] LR: 0.100000
Total Loss: 0.5813 | top1:  80.9100

Epoch: [190 | 350] LR: 0.100000
Total Loss: 0.6856 | top1:  76.8400

Epoch: [191 | 350] LR: 0.100000
Total Loss: 0.5846 | top1:  80.4900

Epoch: [192 | 350] LR: 0.100000
Total Loss: 0.6529 | top1:  79.5500

Epoch: [193 | 350] LR: 0.100000
Total Loss: 0.7486 | top1:  76.0300

Epoch: [194 | 350] LR: 0.100000
Total Loss: 1.0831 | top1:  70.1400

Epoch: [195 | 350] LR: 0.100000
Total Loss: 0.6235 | top1:  79.3200

Epoch: [196 | 350] LR: 0.100000
Total Loss: 0.9806 | top1:  71.0900

Epoch: [197 | 350] LR: 0.100000
Total Loss: 0.6649 | top1:  79.0500

Epoch: [198 | 350] LR: 0.100000
Total Loss: 0.6500 | top1:  79.9800

Epoch: [199 | 350] LR: 0.100000
Total Loss: 0.8859 | top1:  72.3100

Epoch: [200 | 350] LR: 0.100000
Total Loss: 0.7178 | top1:  77.1900

Epoch: [201 | 350] LR: 0.100000
########Model after pruning########
module.conv1
Weight:  12.73%,  25.46%,  34.72%,  42.36%,  44.44%,  42.13%,  48.61%,  46.99%
module.layer1.0.conv1
Weight:   0.04%,   3.47%,  15.02%,  27.30%,  37.24%,  42.49%,  47.44%,  45.49%
module.layer1.0.conv2
Weight:   0.04%,   2.00%,  15.93%,  30.69%,  43.88%,  47.18%,  48.00%,  50.78%
module.layer1.1.conv1
Weight:   1.39%,  11.37%,  25.65%,  40.93%,  48.26%,  51.13%
module.layer1.1.conv2
Weight:   0.78%,   9.90%,  31.29%,  41.71%,  48.74%,  48.22%
module.layer1.2.conv1
Weight:   0.22%,   4.51%,  18.32%,  32.81%,  43.14%,  48.78%,  49.61%,  50.52%
module.layer1.2.conv2
Weight:   0.09%,   2.43%,  16.93%,  33.81%,  42.75%,  49.57%,  50.91%
module.layer2.0.conv1
Weight:   0.98%,  13.93%,  32.34%,  44.60%,  47.59%,  48.74%
module.layer2.0.conv2
Weight:   0.27%,   6.36%,  26.65%,  41.25%,  46.78%,  50.92%
module.layer2.0.downsample.0
Weight:   1.95%,  13.87%,  32.62%,  42.77%,  47.66%,  49.61%,  49.61%,  48.05%
module.layer2.1.conv1
Weight:   0.02%,   2.55%,  19.51%,  37.94%,  46.28%,  49.52%
module.layer2.1.conv2
Weight:   0.03%,   1.35%,  18.22%,  37.43%,  46.12%,  50.33%
module.layer2.2.conv1
Weight:   0.38%,   5.22%,  24.67%,  41.13%,  47.50%,  49.33%
module.layer2.2.conv2
Weight:   0.05%,   1.81%,  17.52%,  37.49%,  44.98%,  50.08%
module.layer3.0.conv1
Weight:   0.01%,   1.19%,  16.38%,  41.30%,  50.41%
module.layer3.0.conv2
Weight:   0.24%,   3.50%,  21.29%,  50.04%
module.layer3.0.downsample.0
Weight:   0.10%,   1.86%,  15.72%,  34.72%,  44.14%,  47.56%,  50.93%,  48.49%
module.layer3.1.conv1
Weight:   0.00%
module.layer3.1.conv2
Weight:   0.00%
module.layer3.2.conv1
Weight:   0.00%
module.layer3.2.conv2
Weight:   0.00%
module.fc
Weight:  12.50%,  31.88%,  38.75%,  46.56%,  46.56%,  50.31%,  49.69%,  52.03%
Bias:    50.00%,  40.00%,  50.00%,  40.00%,  60.00%
 Test Loss after pruning:  0.71789783, Test Acc:  77.19
 Compression rate after pruning [8587072 / 798898]:  10.75 X
Total Loss: 0.5748 | top1:  82.4500

Epoch: [202 | 350] LR: 0.100000
Total Loss: 0.4689 | top1:  85.0000

Epoch: [203 | 350] LR: 0.100000
Total Loss: 0.7697 | top1:  76.4000

Epoch: [204 | 350] LR: 0.100000
Total Loss: 0.4992 | top1:  84.0300

Epoch: [205 | 350] LR: 0.100000
Total Loss: 0.4566 | top1:  84.9200

Epoch: [206 | 350] LR: 0.100000
Total Loss: 0.5280 | top1:  82.6100

Epoch: [207 | 350] LR: 0.100000
Total Loss: 0.4866 | top1:  84.0800

Epoch: [208 | 350] LR: 0.100000
Total Loss: 0.6238 | top1:  80.3700

Epoch: [209 | 350] LR: 0.100000
Total Loss: 0.4739 | top1:  84.6100

Epoch: [210 | 350] LR: 0.100000
Total Loss: 0.5802 | top1:  81.7700

Epoch: [211 | 350] LR: 0.100000
Total Loss: 0.5539 | top1:  81.9800

Epoch: [212 | 350] LR: 0.100000
Total Loss: 0.7111 | top1:  78.2800

Epoch: [213 | 350] LR: 0.100000
Total Loss: 0.6673 | top1:  78.4100

Epoch: [214 | 350] LR: 0.100000
Total Loss: 0.6979 | top1:  78.1900

Epoch: [215 | 350] LR: 0.100000
Total Loss: 0.6850 | top1:  79.5100

Epoch: [216 | 350] LR: 0.100000
Total Loss: 0.7924 | top1:  74.4300

Epoch: [217 | 350] LR: 0.100000
Total Loss: 1.1678 | top1:  65.5300

Epoch: [218 | 350] LR: 0.100000
Total Loss: 0.7396 | top1:  76.4200

Epoch: [219 | 350] LR: 0.100000
Total Loss: 0.5773 | top1:  80.3900

Epoch: [220 | 350] LR: 0.100000
Total Loss: 0.7471 | top1:  77.5200

Epoch: [221 | 350] LR: 0.100000
Total Loss: 0.6404 | top1:  78.7500

Epoch: [222 | 350] LR: 0.100000
Total Loss: 0.8802 | top1:  74.4000

Epoch: [223 | 350] LR: 0.100000
Total Loss: 1.2877 | top1:  64.5100

Epoch: [224 | 350] LR: 0.100000
Total Loss: 0.7480 | top1:  75.7000

Epoch: [225 | 350] LR: 0.100000
Total Loss: 1.1517 | top1:  68.3400

Epoch: [226 | 350] LR: 0.100000
Total Loss: 0.9444 | top1:  73.6700

Epoch: [227 | 350] LR: 0.100000
Total Loss: 0.8755 | top1:  71.9800

Epoch: [228 | 350] LR: 0.100000
Total Loss: 0.6555 | top1:  78.7000

Epoch: [229 | 350] LR: 0.100000
Total Loss: 0.6830 | top1:  76.9500

Epoch: [230 | 350] LR: 0.100000
Total Loss: 0.7331 | top1:  75.9800

Epoch: [231 | 350] LR: 0.100000
Total Loss: 0.6644 | top1:  78.7000

Epoch: [232 | 350] LR: 0.100000
Total Loss: 0.8189 | top1:  74.1900

Epoch: [233 | 350] LR: 0.100000
Total Loss: 0.6091 | top1:  79.1600

Epoch: [234 | 350] LR: 0.100000
Total Loss: 0.7722 | top1:  75.8900

Epoch: [235 | 350] LR: 0.100000
Total Loss: 0.6387 | top1:  78.2200

Epoch: [236 | 350] LR: 0.100000
Total Loss: 0.8830 | top1:  74.8100

Epoch: [237 | 350] LR: 0.100000
Total Loss: 0.7236 | top1:  77.3900

Epoch: [238 | 350] LR: 0.100000
Total Loss: 0.8176 | top1:  73.9100

Epoch: [239 | 350] LR: 0.100000
Total Loss: 0.9454 | top1:  69.7900

Epoch: [240 | 350] LR: 0.100000
Total Loss: 0.6385 | top1:  78.8100

Epoch: [241 | 350] LR: 0.100000
Total Loss: 0.7442 | top1:  76.2100

Epoch: [242 | 350] LR: 0.100000
Total Loss: 0.6811 | top1:  77.8300

Epoch: [243 | 350] LR: 0.100000
Total Loss: 0.7105 | top1:  76.5500

Epoch: [244 | 350] LR: 0.100000
Total Loss: 0.6629 | top1:  77.0900

Epoch: [245 | 350] LR: 0.100000
Total Loss: 0.6426 | top1:  79.4300

Epoch: [246 | 350] LR: 0.100000
Total Loss: 0.8256 | top1:  74.5700

Epoch: [247 | 350] LR: 0.100000
Total Loss: 0.6424 | top1:  79.4000

Epoch: [248 | 350] LR: 0.100000
Total Loss: 0.7308 | top1:  76.8400

Epoch: [249 | 350] LR: 0.100000
Total Loss: 0.7246 | top1:  77.4600

Epoch: [250 | 350] LR: 0.100000
Total Loss: 0.6287 | top1:  79.5300

Epoch: [251 | 350] LR: 0.010000
Total Loss: 0.3363 | top1:  88.3300

Epoch: [252 | 350] LR: 0.010000
Total Loss: 0.3358 | top1:  89.0100

Epoch: [253 | 350] LR: 0.010000
Total Loss: 0.3284 | top1:  88.9200

Epoch: [254 | 350] LR: 0.010000
Total Loss: 0.3352 | top1:  88.7500

Epoch: [255 | 350] LR: 0.010000
Total Loss: 0.3175 | top1:  89.4700

Epoch: [256 | 350] LR: 0.010000
Total Loss: 0.3355 | top1:  89.1500

Epoch: [257 | 350] LR: 0.010000
Total Loss: 0.3413 | top1:  88.9600

Epoch: [258 | 350] LR: 0.010000
Total Loss: 0.3380 | top1:  89.1800

Epoch: [259 | 350] LR: 0.010000
Total Loss: 0.3312 | top1:  89.2100

Epoch: [260 | 350] LR: 0.010000
Total Loss: 0.3226 | top1:  89.5200

Epoch: [261 | 350] LR: 0.010000
Total Loss: 0.3185 | top1:  89.5400

Epoch: [262 | 350] LR: 0.010000
Total Loss: 0.3283 | top1:  89.0800

Epoch: [263 | 350] LR: 0.010000
Total Loss: 0.3273 | top1:  89.5300

Epoch: [264 | 350] LR: 0.010000
Total Loss: 0.3756 | top1:  88.0000

Epoch: [265 | 350] LR: 0.010000
Total Loss: 0.3707 | top1:  87.6700

Epoch: [266 | 350] LR: 0.010000
Total Loss: 0.3287 | top1:  88.9600

Epoch: [267 | 350] LR: 0.010000
Total Loss: 0.3404 | top1:  88.9600

Epoch: [268 | 350] LR: 0.010000
Total Loss: 0.3786 | top1:  88.0200

Epoch: [269 | 350] LR: 0.010000
Total Loss: 0.4048 | top1:  87.6000

Epoch: [270 | 350] LR: 0.010000
Total Loss: 0.3452 | top1:  89.0100

Epoch: [271 | 350] LR: 0.010000
Total Loss: 0.3595 | top1:  88.3500

Epoch: [272 | 350] LR: 0.010000
Total Loss: 0.3565 | top1:  88.7500

Epoch: [273 | 350] LR: 0.010000
Total Loss: 0.3993 | top1:  87.5600

Epoch: [274 | 350] LR: 0.010000
Total Loss: 0.3670 | top1:  88.0600

Epoch: [275 | 350] LR: 0.010000
Total Loss: 0.3785 | top1:  88.3000

Epoch: [276 | 350] LR: 0.010000
Total Loss: 0.3712 | top1:  87.8200

Epoch: [277 | 350] LR: 0.010000
Total Loss: 0.3331 | top1:  89.1700

Epoch: [278 | 350] LR: 0.010000
Total Loss: 0.3339 | top1:  89.0000

Epoch: [279 | 350] LR: 0.010000
Total Loss: 0.3633 | top1:  88.1600

Epoch: [280 | 350] LR: 0.010000
Total Loss: 0.3483 | top1:  88.5900

Epoch: [281 | 350] LR: 0.010000
Total Loss: 0.4563 | top1:  85.9500

Epoch: [282 | 350] LR: 0.010000
Total Loss: 0.3674 | top1:  88.6200

Epoch: [283 | 350] LR: 0.010000
Total Loss: 0.3268 | top1:  89.0200

Epoch: [284 | 350] LR: 0.010000
Total Loss: 0.4274 | top1:  86.7800

Epoch: [285 | 350] LR: 0.010000
Total Loss: 0.3924 | top1:  87.5400

Epoch: [286 | 350] LR: 0.010000
Total Loss: 0.4838 | top1:  85.7500

Epoch: [287 | 350] LR: 0.010000
Total Loss: 0.3865 | top1:  88.1700

Epoch: [288 | 350] LR: 0.010000
Total Loss: 0.5121 | top1:  84.9200

Epoch: [289 | 350] LR: 0.010000
Total Loss: 0.5007 | top1:  85.5400

Epoch: [290 | 350] LR: 0.010000
Total Loss: 0.4013 | top1:  87.3300

Epoch: [291 | 350] LR: 0.010000
Total Loss: 0.3675 | top1:  88.2800

Epoch: [292 | 350] LR: 0.010000
Total Loss: 0.3737 | top1:  87.9500

Epoch: [293 | 350] LR: 0.010000
Total Loss: 0.3968 | top1:  87.4800

Epoch: [294 | 350] LR: 0.010000
Total Loss: 0.3709 | top1:  88.0900

Epoch: [295 | 350] LR: 0.010000
Total Loss: 0.4145 | top1:  86.9800

Epoch: [296 | 350] LR: 0.010000
Total Loss: 0.4153 | top1:  87.2900

Epoch: [297 | 350] LR: 0.010000
Total Loss: 0.4530 | top1:  86.2800

Epoch: [298 | 350] LR: 0.010000
Total Loss: 0.3682 | top1:  88.1400

Epoch: [299 | 350] LR: 0.010000
Total Loss: 0.4463 | top1:  85.3200

Epoch: [300 | 350] LR: 0.010000
Total Loss: 0.3510 | top1:  88.8100

Epoch: [301 | 350] LR: 0.010000
########Model after pruning########
module.conv1
Weight:   9.72%,  19.44%,  33.56%,  41.44%,  43.98%,  48.61%,  47.69%,  45.37%
module.layer1.0.conv1
Weight:   0.69%,   8.25%,  20.36%,  35.33%,  42.75%,  46.14%,  47.70%
module.layer1.0.conv2
Weight:   0.17%,   6.77%,  24.31%,  39.93%,  44.18%,  48.61%,  50.35%
module.layer1.1.conv1
Weight:   0.39%,   6.55%,  25.95%,  42.75%,  51.30%
module.layer1.1.conv2
Weight:   0.22%,   5.47%,  26.61%,  45.96%,  50.78%
module.layer1.2.conv1
Weight:   1.22%,  11.89%,  26.82%,  42.45%,  45.88%,  49.44%,  50.78%
module.layer1.2.conv2
Weight:   0.43%,   8.55%,  27.13%,  42.75%,  48.52%,  52.08%
module.layer2.0.conv1
Weight:   0.17%,   6.88%,  27.86%,  44.77%,  49.18%
module.layer2.0.conv2
Weight:   1.81%,  19.43%,  41.89%,  50.46%
module.layer2.0.downsample.0
Weight:   0.78%,   8.79%,  29.10%,  38.28%,  45.51%,  46.29%,  46.68%,  48.83%
module.layer2.1.conv1
Weight:   0.52%,  12.55%,  38.67%,  50.62%
module.layer2.1.conv2
Weight:   0.16%,   9.84%,  38.38%,  51.71%
module.layer2.2.conv1
Weight:   0.04%,   1.83%,  17.52%,  42.39%,  51.16%
module.layer2.2.conv2
Weight:   0.01%,   0.29%,   9.10%,  36.32%,  51.07%
module.layer3.0.conv1
Weight:   0.15%,  10.85%,  49.10%
module.layer3.0.conv2
Weight:   0.22%,  13.70%
module.layer3.0.downsample.0
Weight:   0.34%,   5.86%,  24.41%,  39.50%,  45.80%,  48.05%,  48.34%
module.layer3.1.conv1
Weight:   0.00%
module.layer3.1.conv2
Weight:   0.00%
module.layer3.2.conv1
Weight:   0.00%
module.layer3.2.conv2
Weight:   0.00%
module.fc
Weight:   9.84%,  27.97%,  41.72%,  50.78%,  45.16%,  50.78%,  48.12%,  49.06%
Bias:    10.00%,  70.00%,  20.00%,  70.00%
 Test Loss after pruning:  0.35124821, Test Acc:  88.81
 Compression rate after pruning [8587072 / 596136]:  14.40 X
Total Loss: 0.3096 | top1:  90.1700

Epoch: [302 | 350] LR: 0.010000
Total Loss: 0.3074 | top1:  90.3100

Epoch: [303 | 350] LR: 0.010000
Total Loss: 0.3103 | top1:  90.2900

Epoch: [304 | 350] LR: 0.010000
Total Loss: 0.3183 | top1:  90.5100

Epoch: [305 | 350] LR: 0.010000
Total Loss: 0.3061 | top1:  90.5300

Epoch: [306 | 350] LR: 0.010000
Total Loss: 0.3132 | top1:  90.2300

Epoch: [307 | 350] LR: 0.010000
Total Loss: 0.3166 | top1:  90.2900

Epoch: [308 | 350] LR: 0.010000
Total Loss: 0.3162 | top1:  90.5200

Epoch: [309 | 350] LR: 0.010000
Total Loss: 0.3076 | top1:  90.5300

Epoch: [310 | 350] LR: 0.010000
Total Loss: 0.3204 | top1:  90.0900

Epoch: [311 | 350] LR: 0.010000
Total Loss: 0.3020 | top1:  90.5900

Epoch: [312 | 350] LR: 0.010000
Total Loss: 0.3103 | top1:  90.2100

Epoch: [313 | 350] LR: 0.010000
Total Loss: 0.3087 | top1:  90.5900

Epoch: [314 | 350] LR: 0.010000
Total Loss: 0.3184 | top1:  90.4800

Epoch: [315 | 350] LR: 0.010000
Total Loss: 0.3067 | top1:  90.5600

Epoch: [316 | 350] LR: 0.010000
Total Loss: 0.3193 | top1:  90.2600

Epoch: [317 | 350] LR: 0.010000
Total Loss: 0.3459 | top1:  89.6700

Epoch: [318 | 350] LR: 0.010000
Total Loss: 0.3295 | top1:  89.8100

Epoch: [319 | 350] LR: 0.010000
Total Loss: 0.3030 | top1:  90.4400

Epoch: [320 | 350] LR: 0.010000
Total Loss: 0.3089 | top1:  90.5300

Epoch: [321 | 350] LR: 0.010000
Total Loss: 0.3268 | top1:  89.9800

Epoch: [322 | 350] LR: 0.010000
Total Loss: 0.3244 | top1:  90.2100

Epoch: [323 | 350] LR: 0.010000
Total Loss: 0.3200 | top1:  90.2200

Epoch: [324 | 350] LR: 0.010000
Total Loss: 0.3272 | top1:  90.2900

Epoch: [325 | 350] LR: 0.010000
Total Loss: 0.3229 | top1:  89.9700

Epoch: [326 | 350] LR: 0.010000
Total Loss: 0.3342 | top1:  89.7700

Epoch: [327 | 350] LR: 0.010000
Total Loss: 0.3269 | top1:  89.8200

Epoch: [328 | 350] LR: 0.010000
Total Loss: 0.3330 | top1:  89.8200

Epoch: [329 | 350] LR: 0.010000
Total Loss: 0.3121 | top1:  90.6700

Epoch: [330 | 350] LR: 0.010000
Total Loss: 0.3159 | top1:  90.2000

Epoch: [331 | 350] LR: 0.010000
Total Loss: 0.3275 | top1:  89.7200

Epoch: [332 | 350] LR: 0.010000
Total Loss: 0.3236 | top1:  90.4500

Epoch: [333 | 350] LR: 0.010000
Total Loss: 0.3193 | top1:  90.1000

Epoch: [334 | 350] LR: 0.010000
Total Loss: 0.3376 | top1:  89.6000

Epoch: [335 | 350] LR: 0.010000
Total Loss: 0.3517 | top1:  89.1800

Epoch: [336 | 350] LR: 0.010000
Total Loss: 0.2985 | top1:  90.7100

Epoch: [337 | 350] LR: 0.010000
Total Loss: 0.3564 | top1:  89.6100

Epoch: [338 | 350] LR: 0.010000
Total Loss: 0.3290 | top1:  90.0200

Epoch: [339 | 350] LR: 0.010000
Total Loss: 0.3287 | top1:  90.1500

Epoch: [340 | 350] LR: 0.010000
Total Loss: 0.3288 | top1:  89.2600

Epoch: [341 | 350] LR: 0.010000
Total Loss: 0.3483 | top1:  89.4700

Epoch: [342 | 350] LR: 0.010000
Total Loss: 0.3269 | top1:  89.9500

Epoch: [343 | 350] LR: 0.010000
Total Loss: 0.3651 | top1:  89.8500

Epoch: [344 | 350] LR: 0.010000
Total Loss: 0.3164 | top1:  90.2400

Epoch: [345 | 350] LR: 0.010000
Total Loss: 0.3143 | top1:  90.6200

Epoch: [346 | 350] LR: 0.010000
Total Loss: 0.3485 | top1:  89.3300

Epoch: [347 | 350] LR: 0.010000
Total Loss: 0.3621 | top1:  89.4000

Epoch: [348 | 350] LR: 0.010000
Total Loss: 0.3459 | top1:  89.9300

Epoch: [349 | 350] LR: 0.010000
Total Loss: 0.3208 | top1:  90.1800

Epoch: [350 | 350] LR: 0.010000
Total Loss: 0.3249 | top1:  89.8800
Final checkpoint:
module.conv1
Weight:   7.41%,  16.90%,  32.18%,  37.50%,  44.21%,  47.69%,  48.61%,  47.92%
module.layer1.0.conv1
Weight:   4.77%,  16.10%,  32.16%,  42.14%,  45.31%,  48.87%
module.layer1.0.conv2
Weight:   2.13%,  19.53%,  35.98%,  45.18%,  48.31%,  51.95%
module.layer1.1.conv1
Weight:   3.30%,  20.75%,  41.75%,  49.65%
module.layer1.1.conv2
Weight:   2.21%,  20.92%,  44.05%,  48.65%
module.layer1.2.conv1
Weight:   0.26%,   6.73%,  21.48%,  40.80%,  46.14%,  47.44%,  50.69%
module.layer1.2.conv2
Weight:   0.09%,   3.78%,  22.22%,  41.15%,  46.66%,  49.00%
module.layer2.0.conv1
Weight:   2.76%,  21.96%,  42.45%,  51.09%
module.layer2.0.conv2
Weight:   0.18%,  11.33%,  38.42%,  51.36%
module.layer2.0.downsample.0
Weight:   0.39%,   5.08%,  25.39%,  39.06%,  48.83%,  47.66%,  52.15%,  51.17%
module.layer2.1.conv1
Weight:   5.24%,  34.44%,  52.80%
module.layer2.1.conv2
Weight:   3.69%,  34.27%,  50.92%
module.layer2.2.conv1
Weight:   0.33%,  10.90%,  39.91%,  50.59%
module.layer2.2.conv2
Weight:   0.01%,   3.84%,  32.07%,  51.39%
module.layer3.0.conv1
Weight:   5.26%,  53.63%
module.layer3.0.conv2
Weight:  13.91%
module.layer3.0.downsample.0
Weight:   2.10%,  17.29%,  37.79%,  43.51%,  47.80%,  50.73%
module.layer3.1.conv1
Weight:   0.00%
module.layer3.1.conv2
Weight:   0.00%
module.layer3.2.conv1
Weight:   0.00%
module.layer3.2.conv2
Weight:   0.00%
module.fc
Weight:   8.75%,  27.34%,  41.41%,  50.62%,  49.38%,  48.44%,  52.81%,  48.44%
Bias:    10.00%,  50.00%,  30.00%,  50.00%
 Final compression rate [8587072 / 490152]:  17.52 X
Total Loss: 0.3252 | top1:  89.9000
Best acc:
90.71
